{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "za8kl_PE8Ss6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Vt37I1K5ubdB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPARATION"
      ],
      "metadata": {
        "id": "GmvkXfWw8Zua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOX7TEk6uixg",
        "outputId": "4619dd7d-a852-4f7e-931a-fe7ee3032d96"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload vegemite.csv to Colab first\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/vegemite.csv')\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(f\"Original class distribution:\\n{df.iloc[:, -1].value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1fQBdIGui2W",
        "outputId": "fe0a2e75-234d-4473-cf8c-eed9de7c550c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (15237, 47)\n",
            "Original class distribution:\n",
            "Class\n",
            "2    7548\n",
            "1    5047\n",
            "0    2642\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "constant_columns = []\n",
        "for col in df.columns[:-1]:  # Exclude target column\n",
        "    if df[col].nunique() <= 1:  # Only one unique value (constant)\n",
        "        constant_columns.append(col)\n",
        "        print(f\"Constant column found: {col} (unique values: {df[col].nunique()})\")\n",
        "\n",
        "if constant_columns:\n",
        "    df = df.drop(columns=constant_columns)\n",
        "    print(f\"Removed {len(constant_columns)} constant columns\")\n",
        "else:\n",
        "    print(\"No constant value columns found - Good!\")\n",
        "\n",
        "print(f\"Dataset shape after constant column removal: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-M_JJlGlXK8",
        "outputId": "9665ec32-5144-40c5-d9e3-9a657a30cade"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant column found: TFE Steam temperature SP (unique values: 1)\n",
            "Constant column found: TFE Product out temperature (unique values: 1)\n",
            "Removed 2 constant columns\n",
            "Dataset shape after constant column removal: (15237, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle and split data\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "target_col = df_shuffled.columns[-1]\n",
        "X = df_shuffled.drop(target_col, axis=1)\n",
        "y = df_shuffled[target_col]\n",
        "\n",
        "X_train_temp, X_test, y_train_temp, y_test = train_test_split(\n",
        "    X, y, test_size=1000, stratify=y, random_state=42\n",
        ")\n",
        "print(f\"Test samples: {len(X_test)}, Training samples: {len(X_train_temp)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hgrul5Bui4z",
        "outputId": "33b03d2d-e693-47a9-ce6e-36282b884a64"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test samples: 1000, Training samples: 14237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does the dataset have any constant value columns?"
      ],
      "metadata": {
        "id": "RA6-eVvwU7Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_threshold = 10\n",
        "converted_cols = []\n",
        "\n",
        "for col in X_train_temp.columns:\n",
        "    unique_count = X_train_temp[col].nunique()\n",
        "    if unique_count <= categorical_threshold and unique_count > 1:\n",
        "        # Check if values are integers\n",
        "        if X_train_temp[col].dtype in ['int64', 'int32'] or all(X_train_temp[col].dropna().apply(lambda x: float(x).is_integer())):\n",
        "            converted_cols.append(col)\n",
        "            X_train_temp[col] = X_train_temp[col].astype('category')\n",
        "            X_test[col] = X_test[col].astype('category')\n",
        "            print(f\"Converted {col} to categorical (unique values: {unique_count})\")\n",
        "\n",
        "print(f\"Total converted to categorical: {len(converted_cols)} columns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_WpKlB_ui7R",
        "outputId": "47cce208-fed2-4fd5-a88c-fac9a6d9b359"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted FFTE Feed tank level SP to categorical (unique values: 3)\n",
            "Converted FFTE Pump 1 to categorical (unique values: 5)\n",
            "Converted FFTE Pump 1 - 2 to categorical (unique values: 4)\n",
            "Converted FFTE Pump 2 to categorical (unique values: 5)\n",
            "Converted TFE Motor speed to categorical (unique values: 3)\n",
            "Total converted to categorical: 5 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for missing values and handle them"
      ],
      "metadata": {
        "id": "ZYeKG2Z9VL2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# More robust missing value handling\n",
        "missing_counts = X_train_temp.isnull().sum()\n",
        "columns_with_missing = missing_counts[missing_counts > 0]\n",
        "\n",
        "if len(columns_with_missing) > 0:\n",
        "    print(\"Columns with missing values:\")\n",
        "    for col, count in columns_with_missing.items():\n",
        "        percentage = (count / len(X_train_temp)) * 100\n",
        "        print(f\"  {col}: {count} missing values ({percentage:.2f}%)\")\n",
        "\n",
        "    print(\"\\nApplying robust imputation for missing values...\")\n",
        "\n",
        "    # Separate numeric and categorical columns for imputation\n",
        "    numeric_cols = X_train_temp.select_dtypes(include=[np.number]).columns\n",
        "    categorical_cols = X_train_temp.select_dtypes(include=['category']).columns\n",
        "\n",
        "    # Impute numeric columns with MEDIAN (more robust than mean for outliers)\n",
        "    if len(numeric_cols) > 0:\n",
        "        numeric_imputer = SimpleImputer(strategy='median')  # Changed from 'mean'\n",
        "        X_train_temp[numeric_cols] = numeric_imputer.fit_transform(X_train_temp[numeric_cols])\n",
        "        X_test[numeric_cols] = numeric_imputer.transform(X_test[numeric_cols])\n",
        "        print(f\"Applied median imputation to {len(numeric_cols)} numeric columns\")\n",
        "\n",
        "    # Impute categorical columns with most frequent\n",
        "    if len(categorical_cols) > 0:\n",
        "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "        X_train_temp[categorical_cols] = categorical_imputer.fit_transform(X_train_temp[categorical_cols])\n",
        "        X_test[categorical_cols] = categorical_imputer.transform(X_test[categorical_cols])\n",
        "        print(f\"Applied mode imputation to {len(categorical_cols)} categorical columns\")\n",
        "\n",
        "    print(\"Enhanced missing value imputation completed!\")\n",
        "else:\n",
        "    print(\"No missing values found - Dataset is clean!\")\n",
        "    print(\"Note: This is excellent data quality, but our pipeline is ready for missing values if they occur.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHZGyLdLui9z",
        "outputId": "e62440d6-8256-4797-c09e-59de60aef9a3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values found - Dataset is clean!\n",
            "Note: This is excellent data quality, but our pipeline is ready for missing values if they occur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class balance analysis and correction"
      ],
      "metadata": {
        "id": "FWsn-lL2VN6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_dist = y_train_temp.value_counts().sort_index()\n",
        "print(\"\\nClass distribution:\")\n",
        "for class_val, count in class_dist.items():\n",
        "    percentage = (count / len(y_train_temp)) * 100\n",
        "    print(f\"  Class {class_val}: {count} samples ({percentage:.1f}%)\")\n",
        "\n",
        "imbalance_ratio = class_dist.max() / class_dist.min()\n",
        "print(f\"Class imbalance ratio: {imbalance_ratio:.2f}\")\n",
        "\n",
        "if imbalance_ratio > 1.5:\n",
        "    print(\"Class imbalance detected (ratio > 1.5). Applying SMOTE...\")\n",
        "    # Convert categorical columns to numeric for SMOTE\n",
        "    X_train_for_smote = X_train_temp.copy()\n",
        "    categorical_cols = X_train_temp.select_dtypes(include=['category']).columns\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        X_train_for_smote[col] = X_train_for_smote[col].cat.codes\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_for_smote, y_train_temp)\n",
        "\n",
        "    # Convert back to DataFrame\n",
        "    X_train_balanced = pd.DataFrame(X_train_balanced, columns=X_train_temp.columns)\n",
        "\n",
        "    print(\"After SMOTE balancing:\")\n",
        "    balanced_dist = pd.Series(y_train_balanced).value_counts().sort_index()\n",
        "    for class_val, count in balanced_dist.items():\n",
        "        percentage = (count / len(y_train_balanced)) * 100\n",
        "        print(f\"  Class {class_val}: {count} samples ({percentage:.1f}%)\")\n",
        "else:\n",
        "    X_train_balanced, y_train_balanced = X_train_temp, y_train_temp\n",
        "    print(\"Classes are reasonably balanced - no SMOTE needed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b49qmZRDujAK",
        "outputId": "ac3c399b-ea26-4f87-ad91-ace89042e90f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class distribution:\n",
            "  Class 0: 2468 samples (17.3%)\n",
            "  Class 1: 4716 samples (33.1%)\n",
            "  Class 2: 7053 samples (49.5%)\n",
            "Class imbalance ratio: 2.86\n",
            "Class imbalance detected (ratio > 1.5). Applying SMOTE...\n",
            "After SMOTE balancing:\n",
            "  Class 0: 7053 samples (33.3%)\n",
            "  Class 1: 7053 samples (33.3%)\n",
            "  Class 2: 7053 samples (33.3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature exploration and composite features"
      ],
      "metadata": {
        "id": "VLSx6KqnVXln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical columns back to numeric for mathematical operations\n",
        "categorical_cols = X_train_balanced.select_dtypes(include=['category']).columns\n",
        "if len(categorical_cols) > 0:\n",
        "    for col in categorical_cols:\n",
        "        X_train_balanced[col] = X_train_balanced[col].cat.codes\n",
        "\n",
        "# ALSO convert categorical columns in X_test to numeric\n",
        "categorical_cols_test = X_test.select_dtypes(include=['category']).columns\n",
        "if len(categorical_cols_test) > 0:\n",
        "    for col in categorical_cols_test:\n",
        "        X_test[col] = X_test[col].cat.codes\n",
        "\n",
        "numeric_cols = X_train_balanced.select_dtypes(include=[np.number]).columns\n",
        "composite_features = []\n",
        "\n",
        "print(\"Creating composite features based on domain knowledge:\")\n",
        "\n",
        "# Create ratio features between SP and PV columns\n",
        "sp_cols = [col for col in numeric_cols if 'SP' in col]\n",
        "pv_cols = [col for col in numeric_cols if 'PV' in col]\n",
        "\n",
        "print(f\"Found {len(sp_cols)} SP columns and {len(pv_cols)} PV columns\")\n",
        "\n",
        "# SP to PV ratios (limited to avoid too many features)\n",
        "for sp_col in sp_cols[:3]:\n",
        "    base_name = sp_col.replace(' SP', '')\n",
        "    pv_col = base_name + ' PV'\n",
        "    if pv_col in pv_cols:\n",
        "        ratio_col = f\"{base_name}_SP_to_PV_ratio\"\n",
        "        X_train_balanced[ratio_col] = X_train_balanced[sp_col] / (X_train_balanced[pv_col] + 1e-8)\n",
        "        X_test[ratio_col] = X_test[sp_col] / (X_test[pv_col] + 1e-8)\n",
        "        composite_features.append(ratio_col)\n",
        "        print(f\"Created: {ratio_col}\")\n",
        "\n",
        "# Temperature difference features\n",
        "temp_cols = [col for col in numeric_cols if 'Temperature' in col or 'temp' in col.lower()]\n",
        "if len(temp_cols) >= 2:\n",
        "    for i in range(min(2, len(temp_cols)-1)):\n",
        "        diff_col = f\"{temp_cols[i]}_minus_{temp_cols[i+1]}_diff\"\n",
        "        X_train_balanced[diff_col] = X_train_balanced[temp_cols[i]] - X_train_balanced[temp_cols[i+1]]\n",
        "        X_test[diff_col] = X_test[temp_cols[i]] - X_test[temp_cols[i+1]]\n",
        "        composite_features.append(diff_col)\n",
        "        print(f\"Created: {diff_col}\")\n",
        "\n",
        "# Flow rate efficiency features (if flow columns exist)\n",
        "flow_cols = [col for col in numeric_cols if 'flow' in col.lower()]\n",
        "if len(flow_cols) >= 2:\n",
        "    efficiency_col = f\"{flow_cols[0]}_to_{flow_cols[1]}_efficiency\"\n",
        "    X_train_balanced[efficiency_col] = X_train_balanced[flow_cols[0]] / (X_train_balanced[flow_cols[1]] + 1e-8)\n",
        "    X_test[efficiency_col] = X_test[flow_cols[0]] / (X_test[flow_cols[1]] + 1e-8)\n",
        "    composite_features.append(efficiency_col)\n",
        "    print(f\"Created: {efficiency_col}\")\n",
        "\n",
        "print(f\"Total composite features created: {len(composite_features)}\")"
      ],
      "metadata": {
        "id": "qb5dy-9mVnUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6dae23-b00a-46af-8a9c-5fdba7313d20"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating composite features based on domain knowledge:\n",
            "Found 9 SP columns and 11 PV columns\n",
            "Created: FFTE Feed tank level_SP_to_PV_ratio\n",
            "Created: FFTE Production solids_SP_to_PV_ratio\n",
            "Created: FFTE Steam pressure_SP_to_PV_ratio\n",
            "Created: FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff\n",
            "Created: FFTE Heat temperature 1_minus_FFTE Heat temperature 2_diff\n",
            "Created: TFE Out flow SP_to_FFTE Feed flow SP_efficiency\n",
            "Total composite features created: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final feature count"
      ],
      "metadata": {
        "id": "z9_XQrE8mUkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final training set shape: {X_train_balanced.shape}\")\n",
        "print(f\"Final test set shape: {X_test.shape}\")\n",
        "print(f\"Total features in final dataset: {len(X_train_balanced.columns)}\")\n",
        "\n",
        "# Show feature breakdown\n",
        "numeric_final = X_train_balanced.select_dtypes(include=[np.number]).columns\n",
        "categorical_final = X_train_balanced.select_dtypes(include=['category']).columns\n",
        "print(f\"  - Numeric features: {len(numeric_final)}\")\n",
        "print(f\"  - Categorical features: {len(categorical_final)}\")\n",
        "print(f\"  - Original features: {len(X_train_balanced.columns) - len(composite_features)}\")\n",
        "print(f\"  - Composite features: {len(composite_features)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5yz1gJAmXD6",
        "outputId": "feafe40d-1468-4434-9252-0776781c46c0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final training set shape: (21159, 50)\n",
            "Final test set shape: (1000, 50)\n",
            "Total features in final dataset: 50\n",
            "  - Numeric features: 50\n",
            "  - Categorical features: 0\n",
            "  - Original features: 44\n",
            "  - Composite features: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection, Model Training and Evaluation"
      ],
      "metadata": {
        "id": "2zWz5k1_91gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all data is numeric for feature selection\n",
        "X_train_for_selection = X_train_balanced.copy()\n",
        "X_test_for_selection = X_test.copy()\n",
        "\n",
        "# Convert categorical columns to numeric codes if any remain\n",
        "categorical_cols_final = X_train_for_selection.select_dtypes(include=['category']).columns\n",
        "if len(categorical_cols_final) > 0:\n",
        "    for col in categorical_cols_final:\n",
        "        X_train_for_selection[col] = X_train_for_selection[col].cat.codes\n",
        "        X_test_for_selection[col] = X_test_for_selection[col].cat.codes\n",
        "\n",
        "# Final check for any remaining missing values\n",
        "remaining_missing = X_train_for_selection.isnull().sum().sum()\n",
        "if remaining_missing > 0:\n",
        "    final_imputer = SimpleImputer(strategy='mean')\n",
        "    X_train_for_selection = pd.DataFrame(\n",
        "        final_imputer.fit_transform(X_train_for_selection),\n",
        "        columns=X_train_for_selection.columns\n",
        "    )\n",
        "    X_test_for_selection = pd.DataFrame(\n",
        "        final_imputer.transform(X_test_for_selection),\n",
        "        columns=X_test_for_selection.columns\n",
        "    )\n",
        "    print(\"Final imputation completed!\")\n",
        "else:\n",
        "    print(\"No missing values found after preprocessing!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIeIy64xujAF",
        "outputId": "56959a66-7c1f-4cf3-960b-49b221be2c42"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values found after preprocessing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection justification"
      ],
      "metadata": {
        "id": "ROiHGwc1V6zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current feature count: {len(X_train_for_selection.columns)}\")\n",
        "print(\"Benefits of feature selection:\")\n",
        "print(\"  - Reduces overfitting (curse of dimensionality)\")\n",
        "print(\"  - Improves computational efficiency\")\n",
        "print(\"  - Enhances model interpretability\")\n",
        "print(\"  - Removes noise from irrelevant features\")\n",
        "print(\"3. SelectKBest with f_classif will identify most discriminative features\")\n",
        "\n",
        "# Apply feature selection\n",
        "k_features = min(20, len(X_train_for_selection.columns))\n",
        "print(f\"Selecting top {k_features} features using ANOVA F-test (f_classif)...\")\n",
        "\n",
        "selector = SelectKBest(f_classif, k=k_features)\n",
        "X_train_selected = selector.fit_transform(X_train_for_selection, y_train_balanced)\n",
        "X_test_selected = selector.transform(X_test_for_selection)\n",
        "\n",
        "selected_features = X_train_for_selection.columns[selector.get_support()]\n",
        "print(f\"Selected {len(selected_features)} features using SelectKBest\")\n",
        "\n",
        "# Show selected features with their scores\n",
        "feature_scores = selector.scores_[selector.get_support()]\n",
        "feature_ranking = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'F_Score': feature_scores\n",
        "}).sort_values('F_Score', ascending=False)\n",
        "\n",
        "print(\"\\nTop selected features:\")\n",
        "print(feature_ranking.head(10))\n",
        "\n",
        "# Convert back to DataFrames with proper column names\n",
        "X_train_final = pd.DataFrame(X_train_selected, columns=selected_features)\n",
        "X_test_final = pd.DataFrame(X_test_selected, columns=selected_features)\n",
        "\n",
        "# Split for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train_final, y_train_balanced, test_size=0.2, stratify=y_train_balanced, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "lEb-JqB9Vnh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f128826a-2372-4141-e72f-93c5a3474f62"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current feature count: 50\n",
            "Benefits of feature selection:\n",
            "  - Reduces overfitting (curse of dimensionality)\n",
            "  - Improves computational efficiency\n",
            "  - Enhances model interpretability\n",
            "  - Removes noise from irrelevant features\n",
            "3. SelectKBest with f_classif will identify most discriminative features\n",
            "Selecting top 20 features using ANOVA F-test (f_classif)...\n",
            "Selected 20 features using SelectKBest\n",
            "\n",
            "Top selected features:\n",
            "                                              Feature     F_Score\n",
            "2                                     TFE Out flow SP  540.398462\n",
            "12                             FFTE Temperature 3 - 2  523.700497\n",
            "9                              FFTE Temperature 1 - 1  523.394607\n",
            "11                             FFTE Temperature 2 - 1  445.608422\n",
            "15                                    TFE Temperature  401.884428\n",
            "10                             FFTE Temperature 1 - 2  381.049580\n",
            "18  FFTE Heat temperature 1_minus_FFTE Heat temper...  305.126607\n",
            "1                           FFTE Production solids SP  247.166941\n",
            "19    TFE Out flow SP_to_FFTE Feed flow SP_efficiency  225.019168\n",
            "14                              TFE Steam temperature  211.790535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train multiple ML models"
      ],
      "metadata": {
        "id": "yKwDOujgWDkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n7) Training 6 different ML models with optimized hyperparameters:\")\n",
        "\n",
        "models = {\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=20, min_samples_leaf=10),\n",
        "    'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100, max_depth=15),\n",
        "    'SVM': SVC(random_state=42, C=1.0),\n",
        "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'NaiveBayes': GaussianNB()\n",
        "}"
      ],
      "metadata": {
        "id": "uND6tXqjWL8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555dfbb5-464b-4c08-cdd1-40e1cbd049f9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7) Training 6 different ML models with optimized hyperparameters:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model evaluation and comparison"
      ],
      "metadata": {
        "id": "FXOtp8vsWQyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_split, y_train_split)\n",
        "    trained_models[name] = model\n",
        "\n",
        "    y_pred_val = model.predict(X_val_split)\n",
        "    val_accuracy = accuracy_score(y_val_split, y_pred_val)\n",
        "    cv_scores = cross_val_score(model, X_train_final, y_train_balanced, cv=5, scoring='accuracy')\n",
        "\n",
        "    results[name] = {\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'classification_report': classification_report(y_val_split, y_pred_val),\n",
        "        'confusion_matrix': confusion_matrix(y_val_split, y_pred_val)\n",
        "    }"
      ],
      "metadata": {
        "id": "WqM--6Y3WL-k"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(models.keys()),\n",
        "    'Validation_Accuracy': [results[name]['val_accuracy'] for name in models.keys()],\n",
        "    'CV_Mean': [results[name]['cv_mean'] for name in models.keys()],\n",
        "    'CV_Std': [results[name]['cv_std'] for name in models.keys()]\n",
        "}).set_index('Model')\n",
        "\n",
        "print(\"8-9) Model Performance Comparison:\")\n",
        "print(comparison_df.sort_values('Validation_Accuracy', ascending=False))"
      ],
      "metadata": {
        "id": "H26jVIYuWMAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29e195d-7db1-4137-de69-a6af0e5ced5b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8-9) Model Performance Comparison:\n",
            "                    Validation_Accuracy   CV_Mean    CV_Std\n",
            "Model                                                      \n",
            "RandomForest                   0.994565  0.989555  0.005242\n",
            "KNN                            0.935491  0.926556  0.003087\n",
            "DecisionTree                   0.907609  0.889409  0.015974\n",
            "LogisticRegression             0.485350  0.483624  0.006741\n",
            "NaiveBayes                     0.479442  0.467035  0.003730\n",
            "SVM                            0.456522  0.437969  0.006833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best model selection and justification"
      ],
      "metadata": {
        "id": "L5wR3lUMWa-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = comparison_df['Validation_Accuracy'].idxmax()\n",
        "best_model = trained_models[best_model_name]\n",
        "print(f\"\\n10) Best model selection:\")\n",
        "print(f\"Selected model: {best_model_name}\")\n",
        "print(f\"Validation accuracy: {comparison_df.loc[best_model_name, 'Validation_Accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nJustification for selecting {best_model_name}:\")\n",
        "print(\"- Highest validation accuracy\")\n",
        "print(\"- Consistent cross-validation performance\")\n",
        "print(\"- Good generalization capability\")\n",
        "\n",
        "print(f\"\\nClassification Report for {best_model_name}:\")\n",
        "print(results[best_model_name]['classification_report'])"
      ],
      "metadata": {
        "id": "Cg2oC6_JWMCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88c128c-4dab-439e-bbc3-332962810703"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10) Best model selection:\n",
            "Selected model: RandomForest\n",
            "Validation accuracy: 0.9946\n",
            "\n",
            "Justification for selecting RandomForest:\n",
            "- Highest validation accuracy\n",
            "- Consistent cross-validation performance\n",
            "- Good generalization capability\n",
            "\n",
            "Classification Report for RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      1410\n",
            "           1       0.99      0.99      0.99      1411\n",
            "           2       1.00      1.00      1.00      1411\n",
            "\n",
            "    accuracy                           0.99      4232\n",
            "   macro avg       0.99      0.99      0.99      4232\n",
            "weighted avg       0.99      0.99      0.99      4232\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "3acPCJm4WeoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "joblib.dump(best_model, 'best_vegemite_model.pkl')\n",
        "joblib.dump(selector, 'feature_selector.pkl')\n",
        "print(\"11) Model saved successfully\")"
      ],
      "metadata": {
        "id": "j7tfHb8vWMEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab6584c-73bf-4b94-922f-c479db953c71"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11) Model saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML TO AI DEPLOYMENT"
      ],
      "metadata": {
        "id": "-2kxqXnbWk4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and test on unseen data"
      ],
      "metadata": {
        "id": "s7Mp2j-OWn4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Test on Unseen Data\n",
        "loaded_model = joblib.load('best_vegemite_model.pkl')\n",
        "loaded_selector = joblib.load('feature_selector.pkl')\n",
        "\n",
        "# Process test data through the same pipeline\n",
        "X_test_processed = X_test_for_selection.copy()\n",
        "\n",
        "# Apply feature selection\n",
        "X_test_selected = loaded_selector.transform(X_test_processed)\n",
        "X_test_final_processed = pd.DataFrame(X_test_selected, columns=selected_features)"
      ],
      "metadata": {
        "id": "pGzYfB84WMGe"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance measurement on unseen data"
      ],
      "metadata": {
        "id": "TXZMOD8tWyNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = loaded_model.predict(X_test_final_processed)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(f\"12-16) Performance on 1000 unseen data points:\")\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "print(\"\\nConfusion Matrix on Test Data:\")\n",
        "print(confusion_matrix(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "jPS_oQTJWy3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83699f7d-b9d7-4f41-9e00-a881d01db7c9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12-16) Performance on 1000 unseen data points:\n",
            "Test accuracy: 0.9870\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       174\n",
            "           1       0.97      0.99      0.98       331\n",
            "           2       1.00      0.98      0.99       495\n",
            "\n",
            "    accuracy                           0.99      1000\n",
            "   macro avg       0.98      0.99      0.99      1000\n",
            "weighted avg       0.99      0.99      0.99      1000\n",
            "\n",
            "\n",
            "Confusion Matrix on Test Data:\n",
            "[[173   1   0]\n",
            " [  2 329   0]\n",
            " [  2   8 485]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare all models on test data"
      ],
      "metadata": {
        "id": "zAz4cxJnW4G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n17) All models test performance:\")\n",
        "test_results = {}\n",
        "for name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_test_final_processed)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    test_results[name] = accuracy\n",
        "    print(f\"{name}: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nModel Ranking Consistency Analysis:\")\n",
        "print(\"Comparing validation vs test performance to ensure robust model selection\\n\")\n",
        "\n",
        "# Get validation rankings\n",
        "val_ranking = comparison_df.sort_values('Validation_Accuracy', ascending=False)\n",
        "print(\"VALIDATION RANKING:\")\n",
        "for i, (model, row) in enumerate(val_ranking.iterrows(), 1):\n",
        "    print(f\"{i}. {model}: {row['Validation_Accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nTEST RANKING:\")\n",
        "test_ranking = sorted([(name, acc) for name, acc in test_results.items()],\n",
        "                     key=lambda x: x[1], reverse=True)\n",
        "for i, (model, acc) in enumerate(test_ranking, 1):\n",
        "    print(f\"{i}. {model}: {acc:.4f}\")\n",
        "\n",
        "# Check if top model is consistent\n",
        "val_top = val_ranking.index[0]\n",
        "test_top = test_ranking[0][0]\n",
        "\n",
        "print(f\"\\nConsistency Check:\")\n",
        "print(f\"Best on Validation: {val_top}\")\n",
        "print(f\"Best on Test: {test_top}\")\n",
        "\n",
        "if val_top == test_top:\n",
        "    print(\"EXCELLENT: Same model ranks #1 on both validation and test!\")\n",
        "    print(\"This indicates robust model selection and good generalization.\")\n",
        "else:\n",
        "    print(\"CAUTION: Different models rank #1 on validation vs test\")\n",
        "    print(\"This could indicate overfitting or high variance in model performance\")\n",
        "\n",
        "# Calculate rank correlation for robustness\n",
        "val_scores = [comparison_df.loc[name, 'Validation_Accuracy'] for name in comparison_df.index]\n",
        "test_scores = [test_results[name] for name in comparison_df.index]\n",
        "correlation = np.corrcoef(val_scores, test_scores)[0,1]\n",
        "print(f\"\\nValidation-Test Correlation: {correlation:.3f}\")\n",
        "if correlation > 0.8:\n",
        "    print(\"Strong correlation - reliable model ranking\")\n",
        "elif correlation > 0.6:\n",
        "    print(\"Moderate correlation - acceptable ranking reliability\")\n",
        "else:\n",
        "    print(\"Weak correlation - consider more robust validation\")"
      ],
      "metadata": {
        "id": "-a2cCzRrW1Pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fa3eb9-1e77-4139-cb9b-acdea33bb49c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "17) All models test performance:\n",
            "DecisionTree: 0.9070\n",
            "RandomForest: 0.9870\n",
            "SVM: 0.3820\n",
            "LogisticRegression: 0.4660\n",
            "KNN: 0.9190\n",
            "NaiveBayes: 0.4310\n",
            "\n",
            "Model Ranking Consistency Analysis:\n",
            "Comparing validation vs test performance to ensure robust model selection\n",
            "\n",
            "VALIDATION RANKING:\n",
            "1. RandomForest: 0.9946\n",
            "2. KNN: 0.9355\n",
            "3. DecisionTree: 0.9076\n",
            "4. LogisticRegression: 0.4853\n",
            "5. NaiveBayes: 0.4794\n",
            "6. SVM: 0.4565\n",
            "\n",
            "TEST RANKING:\n",
            "1. RandomForest: 0.9870\n",
            "2. KNN: 0.9190\n",
            "3. DecisionTree: 0.9070\n",
            "4. LogisticRegression: 0.4660\n",
            "5. NaiveBayes: 0.4310\n",
            "6. SVM: 0.3820\n",
            "\n",
            "Consistency Check:\n",
            "Best on Validation: RandomForest\n",
            "Best on Test: RandomForest\n",
            "EXCELLENT: Same model ranks #1 on both validation and test!\n",
            "This indicates robust model selection and good generalization.\n",
            "\n",
            "Validation-Test Correlation: 0.998\n",
            "Strong correlation - reliable model ranking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEVELOP RULES FROM ML MODEL"
      ],
      "metadata": {
        "id": "EejjE8tTW92D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCLARIFICATION: SP vs PV Features\")\n",
        "print(\"SP = Set Points (controllable parameters that humans can adjust)\")\n",
        "print(\"PV = Process Variables (machine-generated measurements, not directly controllable)\")\n",
        "print(\"Goal: Extract control rules using only SP features for operational guidance\\n\")\n",
        "\n",
        "# Extract SP features from selected features first\n",
        "sp_features_selected = [col for col in selected_features if 'SP' in col]\n",
        "print(f\"SP features found in TOP selected features: {len(sp_features_selected)}\")\n",
        "\n",
        "if sp_features_selected:\n",
        "    print(\"Using SP features from feature selection (most predictive SP features):\")\n",
        "    for feature in sp_features_selected:\n",
        "        print(f\"  {feature}\")\n",
        "\n",
        "    # Use selected SP features for rules\n",
        "    X_train_sp = X_train_final[sp_features_selected]\n",
        "    sp_features_for_rules = sp_features_selected\n",
        "\n",
        "else:\n",
        "    print(\"No SP features in top selected features.\")\n",
        "    print(\"Extracting ALL available SP features from dataset for rule generation...\")\n",
        "\n",
        "    # Get all SP features from the balanced training set\n",
        "    all_sp_features = [col for col in X_train_balanced.columns if 'SP' in col]\n",
        "    print(f\"Total SP features available in dataset: {len(all_sp_features)}\")\n",
        "\n",
        "    if all_sp_features:\n",
        "        print(\"Available SP features for control rules:\")\n",
        "        for feature in all_sp_features:\n",
        "            print(f\"  {feature}\")\n",
        "\n",
        "        # Use all SP features since none were selected as most predictive\n",
        "        X_train_sp = X_train_balanced[all_sp_features]\n",
        "        sp_features_for_rules = all_sp_features\n",
        "    else:\n",
        "        print(\"No SP features found in dataset!\")\n",
        "        sp_features_for_rules = []\n",
        "\n",
        "# Generate decision rules if SP features exist\n",
        "if len(sp_features_for_rules) > 0:\n",
        "    print(f\"\\nGENERATING CONTROL RULES using {len(sp_features_for_rules)} SP features:\")\n",
        "\n",
        "    # Train decision tree on SP features only for rule extraction\n",
        "    dt_sp = DecisionTreeClassifier(\n",
        "        random_state=42,\n",
        "        max_depth=5,           # Limit depth for interpretable rules\n",
        "        min_samples_split=50,  # Avoid overfitting\n",
        "        min_samples_leaf=25    # Ensure statistical significance\n",
        "    )\n",
        "    dt_sp.fit(X_train_sp, y_train_balanced)\n",
        "\n",
        "    # Export interpretable tree rules\n",
        "    tree_rules = export_text(dt_sp, feature_names=sp_features_for_rules, max_depth=5)\n",
        "    print(\"\\nDECISION TREE CONTROL RULES:\")\n",
        "    print(\"=\"*80)\n",
        "    print(tree_rules)\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Feature importance for control priorities\n",
        "    importance_df = pd.DataFrame({\n",
        "        'SP_Feature': sp_features_for_rules,\n",
        "        'Control_Importance': dt_sp.feature_importances_\n",
        "    }).sort_values('Control_Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nSP FEATURE IMPORTANCE FOR PROCESS CONTROL:\")\n",
        "    print(importance_df)\n",
        "\n",
        "    # Generate practical control recommendations\n",
        "    print(f\"\\nPRACTICAL CONTROL RECOMMENDATIONS:\")\n",
        "    print(\"Based on decision tree analysis, here are the recommended SP ranges:\\n\")\n",
        "\n",
        "    for class_label in sorted(y_train_balanced.unique()):\n",
        "        print(f\"FOR CLASS {class_label} (Target Consistency Level):\")\n",
        "        class_mask = y_train_balanced == class_label\n",
        "\n",
        "        if class_mask.sum() > 0:\n",
        "            # Get samples for this class\n",
        "            class_samples = X_train_sp.loc[class_mask]\n",
        "\n",
        "            # Top 3 most important SP features for control\n",
        "            top_sp_features = importance_df.head(3)['SP_Feature'].tolist()\n",
        "\n",
        "            for feature in top_sp_features:\n",
        "                if feature in class_samples.columns:\n",
        "                    values = class_samples[feature]\n",
        "                    if len(values) > 0:\n",
        "                        q25, q50, q75 = values.quantile([0.25, 0.5, 0.75])\n",
        "                        print(f\"  {feature}\")\n",
        "                        print(f\"    Recommended range: {q25:.2f} to {q75:.2f}\")\n",
        "                        print(f\"    Optimal target: {q50:.2f} (median)\")\n",
        "        print()\n",
        "\n",
        "    print(\"Control rules successfully generated!\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot generate SP-based control rules - no SP features available\")\n",
        "    print(\"This suggests the process may be primarily driven by measured variables (PV) rather than set points\")"
      ],
      "metadata": {
        "id": "sYQcn-3DW961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10444cd8-2ba5-479a-8f2e-26e098f9dc01"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CLARIFICATION: SP vs PV Features\n",
            "SP = Set Points (controllable parameters that humans can adjust)\n",
            "PV = Process Variables (machine-generated measurements, not directly controllable)\n",
            "Goal: Extract control rules using only SP features for operational guidance\n",
            "\n",
            "SP features found in TOP selected features: 7\n",
            "Using SP features from feature selection (most predictive SP features):\n",
            "  FFTE Feed tank level SP\n",
            "  FFTE Production solids SP\n",
            "  TFE Out flow SP\n",
            "  TFE Vacuum pressure SP\n",
            "  FFTE Feed flow SP\n",
            "  FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff\n",
            "  TFE Out flow SP_to_FFTE Feed flow SP_efficiency\n",
            "\n",
            "GENERATING CONTROL RULES using 7 SP features:\n",
            "\n",
            "DECISION TREE CONTROL RULES:\n",
            "================================================================================\n",
            "|--- FFTE Feed flow SP <= 10197.65\n",
            "|   |--- FFTE Feed flow SP <= 9233.66\n",
            "|   |   |--- TFE Out flow SP <= 2170.56\n",
            "|   |   |   |--- FFTE Feed tank level SP <= 1.50\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency <= 0.21\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency >  0.21\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- FFTE Feed tank level SP >  1.50\n",
            "|   |   |   |   |--- FFTE Feed flow SP <= 9202.53\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |   |--- FFTE Feed flow SP >  9202.53\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |--- TFE Out flow SP >  2170.56\n",
            "|   |   |   |--- FFTE Production solids SP <= 41.21\n",
            "|   |   |   |   |--- FFTE Production solids SP <= 40.35\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- FFTE Production solids SP >  40.35\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |--- FFTE Production solids SP >  41.21\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency <= 0.24\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency >  0.24\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |--- FFTE Feed flow SP >  9233.66\n",
            "|   |   |--- TFE Out flow SP <= 2255.63\n",
            "|   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= 4.30\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency <= 0.21\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency >  0.21\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  4.30\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency <= 0.20\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency >  0.20\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |--- TFE Out flow SP >  2255.63\n",
            "|   |   |   |--- TFE Out flow SP <= 2584.54\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency <= 0.27\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency >  0.27\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- TFE Out flow SP >  2584.54\n",
            "|   |   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= 1.71\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  1.71\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|--- FFTE Feed flow SP >  10197.65\n",
            "|   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= -9.06\n",
            "|   |   |--- FFTE Feed flow SP <= 10298.76\n",
            "|   |   |   |--- TFE Out flow SP <= 2844.69\n",
            "|   |   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= -11.06\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  -11.06\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- TFE Out flow SP >  2844.69\n",
            "|   |   |   |   |--- TFE Vacuum pressure SP <= -49.49\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- TFE Vacuum pressure SP >  -49.49\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |--- FFTE Feed flow SP >  10298.76\n",
            "|   |   |   |--- TFE Out flow SP <= 2216.35\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- TFE Out flow SP >  2216.35\n",
            "|   |   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= -11.88\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  -11.88\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  -9.06\n",
            "|   |   |--- TFE Out flow SP <= 2162.85\n",
            "|   |   |   |--- TFE Out flow SP <= 2037.11\n",
            "|   |   |   |   |--- TFE Vacuum pressure SP <= -68.58\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |   |--- TFE Vacuum pressure SP >  -68.58\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |--- TFE Out flow SP >  2037.11\n",
            "|   |   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= -3.51\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  -3.51\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |--- TFE Out flow SP >  2162.85\n",
            "|   |   |   |--- TFE Out flow SP <= 2846.52\n",
            "|   |   |   |   |--- TFE Vacuum pressure SP <= -57.45\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |   |--- TFE Vacuum pressure SP >  -57.45\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |--- TFE Out flow SP >  2846.52\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency <= 0.28\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- TFE Out flow SP_to_FFTE Feed flow SP_efficiency >  0.28\n",
            "|   |   |   |   |   |--- class: 2\n",
            "\n",
            "================================================================================\n",
            "\n",
            "SP FEATURE IMPORTANCE FOR PROCESS CONTROL:\n",
            "                                          SP_Feature  Control_Importance\n",
            "2                                    TFE Out flow SP            0.306181\n",
            "4                                  FFTE Feed flow SP            0.261726\n",
            "5  FFTE Out steam temp SP_minus_FFTE Heat tempera...            0.189960\n",
            "6    TFE Out flow SP_to_FFTE Feed flow SP_efficiency            0.165637\n",
            "1                          FFTE Production solids SP            0.038417\n",
            "0                            FFTE Feed tank level SP            0.023657\n",
            "3                             TFE Vacuum pressure SP            0.014422\n",
            "\n",
            "PRACTICAL CONTROL RECOMMENDATIONS:\n",
            "Based on decision tree analysis, here are the recommended SP ranges:\n",
            "\n",
            "FOR CLASS 0 (Target Consistency Level):\n",
            "  TFE Out flow SP\n",
            "    Recommended range: 2081.93 to 2609.30\n",
            "    Optimal target: 2214.29 (median)\n",
            "  FFTE Feed flow SP\n",
            "    Recommended range: 9400.00 to 10081.59\n",
            "    Optimal target: 9500.00 (median)\n",
            "  FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff\n",
            "    Recommended range: -9.71 to 0.01\n",
            "    Optimal target: -3.32 (median)\n",
            "\n",
            "FOR CLASS 1 (Target Consistency Level):\n",
            "  TFE Out flow SP\n",
            "    Recommended range: 2038.55 to 2679.49\n",
            "    Optimal target: 2192.31 (median)\n",
            "  FFTE Feed flow SP\n",
            "    Recommended range: 9300.00 to 10130.00\n",
            "    Optimal target: 9500.00 (median)\n",
            "  FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff\n",
            "    Recommended range: -8.89 to 1.46\n",
            "    Optimal target: -2.91 (median)\n",
            "\n",
            "FOR CLASS 2 (Target Consistency Level):\n",
            "  TFE Out flow SP\n",
            "    Recommended range: 2174.46 to 2897.65\n",
            "    Optimal target: 2609.30 (median)\n",
            "  FFTE Feed flow SP\n",
            "    Recommended range: 9500.00 to 10300.00\n",
            "    Optimal target: 10130.00 (median)\n",
            "  FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff\n",
            "    Recommended range: -6.12 to 1.34\n",
            "    Optimal target: -1.64 (median)\n",
            "\n",
            "Control rules successfully generated!\n"
          ]
        }
      ]
    }
  ]
}