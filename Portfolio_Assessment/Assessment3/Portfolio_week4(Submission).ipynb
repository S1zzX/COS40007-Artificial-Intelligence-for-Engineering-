{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "za8kl_PE8Ss6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vt37I1K5ubdB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPARATION"
      ],
      "metadata": {
        "id": "GmvkXfWw8Zua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOX7TEk6uixg",
        "outputId": "5e7587f1-246c-491f-ed27-db58f01f8972"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload vegemite.csv to Colab first\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/vegemite.csv')\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(f\"Original class distribution:\\n{df.iloc[:, -1].value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1fQBdIGui2W",
        "outputId": "76eaedd4-83d6-486d-a2a4-e5adbe8516ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (15237, 47)\n",
            "Original class distribution:\n",
            "Class\n",
            "2    7548\n",
            "1    5047\n",
            "0    2642\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "constant_columns = []\n",
        "for col in df.columns[:-1]:  # Exclude target column\n",
        "    if df[col].nunique() <= 1:  # Only one unique value (constant)\n",
        "        constant_columns.append(col)\n",
        "        print(f\"Constant column found: {col} (unique values: {df[col].nunique()})\")\n",
        "\n",
        "if constant_columns:\n",
        "    df = df.drop(columns=constant_columns)\n",
        "    print(f\"Removed {len(constant_columns)} constant columns\")\n",
        "else:\n",
        "    print(\"No constant value columns found - Good!\")\n",
        "\n",
        "print(f\"Dataset shape after constant column removal: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-M_JJlGlXK8",
        "outputId": "0b5eac43-6642-4631-d819-05bc1fd48ae2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant column found: TFE Steam temperature SP (unique values: 1)\n",
            "Constant column found: TFE Product out temperature (unique values: 1)\n",
            "Removed 2 constant columns\n",
            "Dataset shape after constant column removal: (15237, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle and split data\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "target_col = df_shuffled.columns[-1]\n",
        "X = df_shuffled.drop(target_col, axis=1)\n",
        "y = df_shuffled[target_col]\n",
        "\n",
        "# Separate a test set with at least 333 samples per class\n",
        "test_indices = []\n",
        "for class_label in y.unique():\n",
        "    class_indices = y[y == class_label].index.tolist()\n",
        "    # Ensure at least 333 samples if available, otherwise take all\n",
        "    num_samples = min(334, len(class_indices))\n",
        "    test_indices.extend(np.random.choice(class_indices, num_samples, replace=False))\n",
        "\n",
        "X_test = X.loc[test_indices]\n",
        "y_test = y.loc[test_indices]\n",
        "\n",
        "# Use the remaining data for training\n",
        "train_indices = list(set(X.index) - set(test_indices))\n",
        "X_train_temp = X.loc[train_indices]\n",
        "y_train_temp = y.loc[train_indices]\n",
        "\n",
        "print(f\"Test samples: {len(X_test)}, Training samples: {len(X_train_temp)}\")\n",
        "print(f\"Test class distribution:\\n{y_test.value_counts().sort_index()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hgrul5Bui4z",
        "outputId": "dfd27490-33ce-4160-8cfe-8a63877665e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test samples: 1002, Training samples: 14235\n",
            "Test class distribution:\n",
            "Class\n",
            "0    334\n",
            "1    334\n",
            "2    334\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does the dataset have any constant value columns?"
      ],
      "metadata": {
        "id": "RA6-eVvwU7Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_threshold = 10\n",
        "converted_cols = []\n",
        "\n",
        "for col in X_train_temp.columns:\n",
        "    unique_count = X_train_temp[col].nunique()\n",
        "    if unique_count <= categorical_threshold and unique_count > 1:\n",
        "        # Check if values are integers\n",
        "        if X_train_temp[col].dtype in ['int64', 'int32'] or all(X_train_temp[col].dropna().apply(lambda x: float(x).is_integer())):\n",
        "            converted_cols.append(col)\n",
        "            X_train_temp[col] = X_train_temp[col].astype('category')\n",
        "            X_test[col] = X_test[col].astype('category')\n",
        "            print(f\"Converted {col} to categorical (unique values: {unique_count})\")\n",
        "\n",
        "print(f\"Total converted to categorical: {len(converted_cols)} columns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_WpKlB_ui7R",
        "outputId": "5d5714dc-d56e-4eec-c52e-81483680243e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted FFTE Feed tank level SP to categorical (unique values: 3)\n",
            "Converted FFTE Pump 1 to categorical (unique values: 5)\n",
            "Converted FFTE Pump 1 - 2 to categorical (unique values: 4)\n",
            "Converted FFTE Pump 2 to categorical (unique values: 5)\n",
            "Converted TFE Motor speed to categorical (unique values: 3)\n",
            "Total converted to categorical: 5 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for missing values and handle them"
      ],
      "metadata": {
        "id": "ZYeKG2Z9VL2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_counts = X_train_temp.isnull().sum()\n",
        "if missing_counts.sum() > 0:\n",
        "    numeric_cols = X_train_temp.select_dtypes(include=[np.number]).columns\n",
        "    categorical_cols = X_train_temp.select_dtypes(include=['category']).columns\n",
        "\n",
        "    if len(numeric_cols) > 0:\n",
        "        numeric_imputer = SimpleImputer(strategy='median')\n",
        "        X_train_temp[numeric_cols] = numeric_imputer.fit_transform(X_train_temp[numeric_cols])\n",
        "        X_test[numeric_cols] = numeric_imputer.transform(X_test[numeric_cols])\n",
        "\n",
        "    if len(categorical_cols) > 0:\n",
        "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "        X_train_temp[categorical_cols] = categorical_imputer.fit_transform(X_train_temp[categorical_cols])\n",
        "        X_test[categorical_cols] = categorical_imputer.transform(X_test[categorical_cols])\n",
        "    print(\"Missing values imputed\")\n",
        "else:\n",
        "    print(\"No missing values found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHZGyLdLui9z",
        "outputId": "d4220f45-93d3-46d7-8240-72dd9935b6a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class balance analysis and correction"
      ],
      "metadata": {
        "id": "FWsn-lL2VN6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_dist = y_train_temp.value_counts().sort_index()\n",
        "print(f\"\\nClass distribution: {dict(class_dist)}\")\n",
        "imbalance_ratio = class_dist.max() / class_dist.min()\n",
        "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
        "\n",
        "if imbalance_ratio > 1.5:\n",
        "    X_train_for_smote = X_train_temp.copy()\n",
        "    categorical_cols = X_train_temp.select_dtypes(include=['category']).columns\n",
        "    for col in categorical_cols:\n",
        "        X_train_for_smote[col] = X_train_for_smote[col].cat.codes\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_for_smote, y_train_temp)\n",
        "    X_train_balanced = pd.DataFrame(X_train_balanced, columns=X_train_temp.columns)\n",
        "    print(f\"After SMOTE: {dict(pd.Series(y_train_balanced).value_counts().sort_index())}\")\n",
        "else:\n",
        "    X_train_balanced, y_train_balanced = X_train_temp, y_train_temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b49qmZRDujAK",
        "outputId": "4cb712d8-134d-459a-c27b-ef16d42352b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class distribution: {0: np.int64(2308), 1: np.int64(4713), 2: np.int64(7214)}\n",
            "Imbalance ratio: 3.13\n",
            "After SMOTE: {0: np.int64(7214), 1: np.int64(7214), 2: np.int64(7214)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature exploration and composite features"
      ],
      "metadata": {
        "id": "VLSx6KqnVXln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical columns back to numeric for mathematical operations\n",
        "categorical_cols = X_train_balanced.select_dtypes(include=['category']).columns\n",
        "if len(categorical_cols) > 0:\n",
        "    for col in categorical_cols:\n",
        "        X_train_balanced[col] = X_train_balanced[col].cat.codes\n",
        "\n",
        "# ALSO convert categorical columns in X_test to numeric\n",
        "categorical_cols_test = X_test.select_dtypes(include=['category']).columns\n",
        "if len(categorical_cols_test) > 0:\n",
        "    for col in categorical_cols_test:\n",
        "        X_test[col] = X_test[col].cat.codes\n",
        "\n",
        "numeric_cols = X_train_balanced.select_dtypes(include=[np.number]).columns\n",
        "composite_features = []\n",
        "\n",
        "print(\"Creating composite features based on domain knowledge:\")\n",
        "\n",
        "# Create ratio features between SP and PV columns\n",
        "sp_cols = [col for col in numeric_cols if 'SP' in col]\n",
        "pv_cols = [col for col in numeric_cols if 'PV' in col]\n",
        "\n",
        "print(f\"Found {len(sp_cols)} SP columns and {len(pv_cols)} PV columns\")\n",
        "\n",
        "# SP to PV ratios (limited to avoid too many features)\n",
        "for sp_col in sp_cols[:3]:\n",
        "    base_name = sp_col.replace(' SP', '')\n",
        "    pv_col = base_name + ' PV'\n",
        "    if pv_col in pv_cols:\n",
        "        ratio_col = f\"{base_name}_SP_to_PV_ratio\"\n",
        "        X_train_balanced[ratio_col] = X_train_balanced[sp_col] / (X_train_balanced[pv_col] + 1e-8)\n",
        "        X_test[ratio_col] = X_test[sp_col] / (X_test[pv_col] + 1e-8)\n",
        "        composite_features.append(ratio_col)\n",
        "        print(f\"Created: {ratio_col}\")\n",
        "\n",
        "# Temperature difference features\n",
        "temp_cols = [col for col in numeric_cols if 'Temperature' in col or 'temp' in col.lower()]\n",
        "if len(temp_cols) >= 2:\n",
        "    for i in range(min(2, len(temp_cols)-1)):\n",
        "        diff_col = f\"{temp_cols[i]}_minus_{temp_cols[i+1]}_diff\"\n",
        "        X_train_balanced[diff_col] = X_train_balanced[temp_cols[i]] - X_train_balanced[temp_cols[i+1]]\n",
        "        X_test[diff_col] = X_test[temp_cols[i]] - X_test[temp_cols[i+1]]\n",
        "        composite_features.append(diff_col)\n",
        "        print(f\"Created: {diff_col}\")\n",
        "\n",
        "# Flow rate efficiency features (if flow columns exist)\n",
        "flow_cols = [col for col in numeric_cols if 'flow' in col.lower()]\n",
        "if len(flow_cols) >= 2:\n",
        "    efficiency_col = f\"{flow_cols[0]}_to_{flow_cols[1]}_efficiency\"\n",
        "    X_train_balanced[efficiency_col] = X_train_balanced[flow_cols[0]] / (X_train_balanced[flow_cols[1]] + 1e-8)\n",
        "    X_test[efficiency_col] = X_test[flow_cols[0]] / (X_test[flow_cols[1]] + 1e-8)\n",
        "    composite_features.append(efficiency_col)\n",
        "    print(f\"Created: {efficiency_col}\")\n",
        "\n",
        "print(f\"Total composite features created: {len(composite_features)}\")"
      ],
      "metadata": {
        "id": "qb5dy-9mVnUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d278938-acbf-475c-d832-a2a22247a22e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating composite features based on domain knowledge:\n",
            "Found 9 SP columns and 11 PV columns\n",
            "Created: FFTE Feed tank level_SP_to_PV_ratio\n",
            "Created: FFTE Production solids_SP_to_PV_ratio\n",
            "Created: FFTE Steam pressure_SP_to_PV_ratio\n",
            "Created: FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff\n",
            "Created: FFTE Heat temperature 1_minus_FFTE Heat temperature 2_diff\n",
            "Created: TFE Out flow SP_to_FFTE Feed flow SP_efficiency\n",
            "Total composite features created: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final feature count"
      ],
      "metadata": {
        "id": "z9_XQrE8mUkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final training set shape: {X_train_balanced.shape}\")\n",
        "print(f\"Final test set shape: {X_test.shape}\")\n",
        "print(f\"Total features in final dataset: {len(X_train_balanced.columns)}\")\n",
        "\n",
        "# Show feature breakdown\n",
        "numeric_final = X_train_balanced.select_dtypes(include=[np.number]).columns\n",
        "categorical_final = X_train_balanced.select_dtypes(include=['category']).columns\n",
        "print(f\"  - Numeric features: {len(numeric_final)}\")\n",
        "print(f\"  - Categorical features: {len(categorical_final)}\")\n",
        "print(f\"  - Original features: {len(X_train_balanced.columns) - len(composite_features)}\")\n",
        "print(f\"  - Composite features: {len(composite_features)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5yz1gJAmXD6",
        "outputId": "aa6eba28-d32b-48a9-9eee-0ead0d57d6ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final training set shape: (21642, 50)\n",
            "Final test set shape: (1002, 50)\n",
            "Total features in final dataset: 50\n",
            "  - Numeric features: 50\n",
            "  - Categorical features: 0\n",
            "  - Original features: 44\n",
            "  - Composite features: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection, Model Training and Evaluation"
      ],
      "metadata": {
        "id": "2zWz5k1_91gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all data is numeric for feature selection\n",
        "X_train_for_selection = X_train_balanced.copy()\n",
        "X_test_for_selection = X_test.copy()\n",
        "\n",
        "# Convert categorical columns to numeric codes if any remain\n",
        "categorical_cols_final = X_train_for_selection.select_dtypes(include=['category']).columns\n",
        "if len(categorical_cols_final) > 0:\n",
        "    for col in categorical_cols_final:\n",
        "        X_train_for_selection[col] = X_train_for_selection[col].cat.codes\n",
        "        X_test_for_selection[col] = X_test_for_selection[col].cat.codes\n",
        "\n",
        "# Final check for any remaining missing values\n",
        "remaining_missing = X_train_for_selection.isnull().sum().sum()\n",
        "if remaining_missing > 0:\n",
        "    final_imputer = SimpleImputer(strategy='mean')\n",
        "    X_train_for_selection = pd.DataFrame(\n",
        "        final_imputer.fit_transform(X_train_for_selection),\n",
        "        columns=X_train_for_selection.columns\n",
        "    )\n",
        "    X_test_for_selection = pd.DataFrame(\n",
        "        final_imputer.transform(X_test_for_selection),\n",
        "        columns=X_test_for_selection.columns\n",
        "    )\n",
        "    print(\"Final imputation completed!\")\n",
        "else:\n",
        "    print(\"No missing values found after preprocessing!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIeIy64xujAF",
        "outputId": "edc3ba85-4448-4ffa-cbbe-7f97c6207f43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values found after preprocessing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection justification"
      ],
      "metadata": {
        "id": "ROiHGwc1V6zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current feature count: {len(X_train_for_selection.columns)}\")\n",
        "print(\"SelectKBest with f_classif will identify most discriminative features\")\n",
        "\n",
        "# Apply feature selection\n",
        "k_features = min(20, len(X_train_for_selection.columns))\n",
        "print(f\"Selecting top {k_features} features using ANOVA F-test (f_classif)...\")\n",
        "\n",
        "selector = SelectKBest(f_classif, k=k_features)\n",
        "X_train_selected = selector.fit_transform(X_train_for_selection, y_train_balanced)\n",
        "X_test_selected = selector.transform(X_test_for_selection)\n",
        "\n",
        "selected_features = X_train_for_selection.columns[selector.get_support()]\n",
        "print(f\"Selected {len(selected_features)} features using SelectKBest\")\n",
        "\n",
        "# Show selected features with their scores\n",
        "feature_scores = selector.scores_[selector.get_support()]\n",
        "feature_ranking = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'F_Score': feature_scores\n",
        "}).sort_values('F_Score', ascending=False)\n",
        "\n",
        "print(\"\\nTop selected features:\")\n",
        "print(feature_ranking.head(10))\n",
        "\n",
        "# Convert back to DataFrames with proper column names\n",
        "X_train_final = pd.DataFrame(X_train_selected, columns=selected_features)\n",
        "X_test_final = pd.DataFrame(X_test_selected, columns=selected_features)\n",
        "\n",
        "# Split for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train_final, y_train_balanced, test_size=0.2, stratify=y_train_balanced, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "lEb-JqB9Vnh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a252705-0bab-4bad-e013-5df56fcc0088"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current feature count: 50\n",
            "SelectKBest with f_classif will identify most discriminative features\n",
            "Selecting top 20 features using ANOVA F-test (f_classif)...\n",
            "Selected 20 features using SelectKBest\n",
            "\n",
            "Top selected features:\n",
            "                                              Feature     F_Score\n",
            "2                                     TFE Out flow SP  550.151316\n",
            "10                             FFTE Temperature 1 - 1  514.786130\n",
            "13                             FFTE Temperature 3 - 2  513.860299\n",
            "12                             FFTE Temperature 2 - 1  426.796825\n",
            "16                                    TFE Temperature  379.684261\n",
            "11                             FFTE Temperature 1 - 2  356.240231\n",
            "18  FFTE Heat temperature 1_minus_FFTE Heat temper...  285.115353\n",
            "1                           FFTE Production solids SP  270.831639\n",
            "19    TFE Out flow SP_to_FFTE Feed flow SP_efficiency  238.285671\n",
            "15                              TFE Steam temperature  199.779190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train multiple ML models"
      ],
      "metadata": {
        "id": "yKwDOujgWDkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n7) Training 6 different ML models with optimized hyperparameters:\")\n",
        "\n",
        "models = {\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=20, min_samples_leaf=10),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
        "    'SVM': SVC(random_state=42, C=1.0),\n",
        "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'NaiveBayes': GaussianNB()\n",
        "}"
      ],
      "metadata": {
        "id": "uND6tXqjWL8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c2ac7f-175b-4be9-b916-ca74e3bccf4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7) Training 6 different ML models with optimized hyperparameters:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model evaluation and comparison"
      ],
      "metadata": {
        "id": "FXOtp8vsWQyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_split, y_train_split)\n",
        "    trained_models[name] = model\n",
        "\n",
        "    y_pred_val = model.predict(X_val_split)\n",
        "    val_accuracy = accuracy_score(y_val_split, y_pred_val)\n",
        "    cv_scores = cross_val_score(model, X_train_final, y_train_balanced, cv=5, scoring='accuracy')\n",
        "\n",
        "    results[name] = {\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'classification_report': classification_report(y_val_split, y_pred_val),\n",
        "        'confusion_matrix': confusion_matrix(y_val_split, y_pred_val)\n",
        "    }"
      ],
      "metadata": {
        "id": "WqM--6Y3WL-k"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(models.keys()),\n",
        "    'Validation_Accuracy': [results[name]['val_accuracy'] for name in models.keys()],\n",
        "    'CV_Mean': [results[name]['cv_mean'] for name in models.keys()],\n",
        "    'CV_Std': [results[name]['cv_std'] for name in models.keys()]\n",
        "}).set_index('Model')\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(comparison_df.sort_values('Validation_Accuracy', ascending=False))"
      ],
      "metadata": {
        "id": "H26jVIYuWMAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e0f7c4-16c2-4900-8292-a7265d6d5038"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Comparison:\n",
            "                    Validation_Accuracy   CV_Mean    CV_Std\n",
            "Model                                                      \n",
            "RandomForest                   0.974590  0.967701  0.006179\n",
            "KNN                            0.928390  0.931707  0.002250\n",
            "DecisionTree                   0.884038  0.881805  0.014595\n",
            "LogisticRegression             0.473781  0.469966  0.006260\n",
            "NaiveBayes                     0.473550  0.466778  0.005081\n",
            "SVM                            0.447216  0.445153  0.005598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best model selection and justification"
      ],
      "metadata": {
        "id": "L5wR3lUMWa-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = comparison_df['Validation_Accuracy'].idxmax()\n",
        "best_model = trained_models[best_model_name]\n",
        "print(f\"\\n10) Best Model: {best_model_name} (Validation Accuracy: {comparison_df.loc[best_model_name, 'Validation_Accuracy']:.4f})\")\n",
        "print(f\"\\nClassification Report:\\n{results[best_model_name]['classification_report']}\")"
      ],
      "metadata": {
        "id": "Cg2oC6_JWMCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de0b41b-7dfb-47b2-cba4-e804e1184670"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10) Best Model: RandomForest (Validation Accuracy: 0.9746)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      1443\n",
            "           1       0.98      0.95      0.97      1443\n",
            "           2       0.98      0.98      0.98      1443\n",
            "\n",
            "    accuracy                           0.97      4329\n",
            "   macro avg       0.97      0.97      0.97      4329\n",
            "weighted avg       0.97      0.97      0.97      4329\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "3acPCJm4WeoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "joblib.dump(best_model, 'best_vegemite_model.pkl')\n",
        "joblib.dump(selector, 'feature_selector.pkl')\n",
        "print(\"11) Model saved successfully\")"
      ],
      "metadata": {
        "id": "j7tfHb8vWMEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb79be6-77fa-4c04-c632-9cadc6c0966e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11) Model saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML TO AI DEPLOYMENT"
      ],
      "metadata": {
        "id": "-2kxqXnbWk4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and test on unseen data"
      ],
      "metadata": {
        "id": "s7Mp2j-OWn4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Test on Unseen Data\n",
        "loaded_model = joblib.load('best_vegemite_model.pkl')\n",
        "loaded_selector = joblib.load('feature_selector.pkl')\n",
        "\n",
        "# Process test data through the same pipeline\n",
        "X_test_processed = X_test_for_selection.copy()\n",
        "\n",
        "# Apply feature selection\n",
        "X_test_selected = loaded_selector.transform(X_test_processed)\n",
        "X_test_final_processed = pd.DataFrame(X_test_selected, columns=selected_features)\n",
        "correct_predictions = 0\n",
        "for idx in range(len(X_test_final_processed)):\n",
        "    single_row = X_test_final_processed.iloc[idx:idx+1]\n",
        "    prediction = loaded_model.predict(single_row)[0]\n",
        "    actual = y_test.iloc[idx]\n",
        "\n",
        "    # Track correct predictions\n",
        "    if prediction == actual:\n",
        "        correct_predictions += 1\n",
        "\n",
        "    # Print first 10 as examples\n",
        "    if idx < 10:\n",
        "        match_status = \"✓\" if prediction == actual else \"✗\"\n",
        "        print(f\"Row {idx+1}: Predicted={prediction}, Actual={actual} {match_status}\")\n",
        "\n",
        "print(f\"\\nProcessed all {len(X_test_final_processed)} rows individually\")\n",
        "print(f\"Correct predictions: {correct_predictions}/{len(X_test_final_processed)}\")\n",
        "y_pred_test = loaded_model.predict(X_test_final_processed)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "pGzYfB84WMGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6159622d-f129-4589-9ede-5114cc33a324"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 1: Predicted=2, Actual=2 ✓\n",
            "Row 2: Predicted=2, Actual=2 ✓\n",
            "Row 3: Predicted=2, Actual=2 ✓\n",
            "Row 4: Predicted=2, Actual=2 ✓\n",
            "Row 5: Predicted=2, Actual=2 ✓\n",
            "Row 6: Predicted=2, Actual=2 ✓\n",
            "Row 7: Predicted=2, Actual=2 ✓\n",
            "Row 8: Predicted=2, Actual=2 ✓\n",
            "Row 9: Predicted=2, Actual=2 ✓\n",
            "Row 10: Predicted=2, Actual=2 ✓\n",
            "\n",
            "Processed all 1002 rows individually\n",
            "Correct predictions: 980/1002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance measurement on unseen data"
      ],
      "metadata": {
        "id": "TXZMOD8tWyNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Performance on 1002 unseen data points:\")\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "print(\"\\nConfusion Matrix on Test Data:\")\n",
        "print(confusion_matrix(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "jPS_oQTJWy3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616f1f9f-80f1-42f0-903e-cd45f3b1618e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance on 1002 unseen data points:\n",
            "Test accuracy: 0.9780\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       334\n",
            "           1       0.97      0.98      0.98       334\n",
            "           2       0.98      0.97      0.97       334\n",
            "\n",
            "    accuracy                           0.98      1002\n",
            "   macro avg       0.98      0.98      0.98      1002\n",
            "weighted avg       0.98      0.98      0.98      1002\n",
            "\n",
            "\n",
            "Confusion Matrix on Test Data:\n",
            "[[329   1   4]\n",
            " [  3 327   4]\n",
            " [  2   8 324]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare all models on test data"
      ],
      "metadata": {
        "id": "zAz4cxJnW4G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"All Models Test Performance:\")\n",
        "test_results = {}\n",
        "for name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_test_final_processed)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    test_results[name] = accuracy\n",
        "    print(f\"{name}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "-a2cCzRrW1Pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04acf42c-8acb-413a-d00e-6b7b9eb83125"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Models Test Performance:\n",
            "DecisionTree: 0.8473\n",
            "RandomForest: 0.9780\n",
            "SVM: 0.4361\n",
            "LogisticRegression: 0.4481\n",
            "KNN: 0.9132\n",
            "NaiveBayes: 0.4651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e99ce5d9"
      },
      "source": [
        "The text from the PDF is now stored in the `text` variable. You can further process or display it as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEVELOP RULES FROM ML MODEL"
      ],
      "metadata": {
        "id": "EejjE8tTW92D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract SP features from selected features\n",
        "sp_features_in_selection = [col for col in selected_features if 'SP' in col]\n",
        "print(f\"Found {len(sp_features_in_selection)} SP features in selected features:\")\n",
        "for feat in sp_features_in_selection:\n",
        "    print(f\"  - {feat}\")\n",
        "\n",
        "if len(sp_features_in_selection) > 0:\n",
        "    X_train_sp = X_train_final[sp_features_in_selection]\n",
        "\n",
        "    # Train a SIMPLE decision tree for clear rules\n",
        "    print(\"\\nTraining Decision Tree with SP features only...\")\n",
        "    dt_sp = DecisionTreeClassifier(\n",
        "        random_state=42,\n",
        "        max_depth=4,  # Shallow for simple rules\n",
        "        min_samples_split=200,\n",
        "        min_samples_leaf=100\n",
        "    )\n",
        "    dt_sp.fit(X_train_sp, y_train_balanced)\n",
        "\n",
        "    # Print tree rules\n",
        "    tree_rules = export_text(dt_sp, feature_names=sp_features_in_selection, max_depth=4)\n",
        "\n",
        "    print(\"DECISION TREE RULES:\")\n",
        "\n",
        "    print(tree_rules)\n",
        "\n",
        "    # Feature importance\n",
        "\n",
        "    print(\"FEATURE IMPORTANCE:\")\n",
        "\n",
        "    importance_df = pd.DataFrame({\n",
        "        'SP_Feature': sp_features_in_selection,\n",
        "        'Importance': dt_sp.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    print(importance_df)\n",
        "\n",
        "    # Extract SIMPLE rules for each class\n",
        "\n",
        "    print(\"RECOMMENDED SET POINT RANGES FOR EACH CLASS\")\n",
        "\n",
        "\n",
        "    for class_label in sorted(y_train_balanced.unique()):\n",
        "\n",
        "        print(f\"CLASS {class_label} - Recommended Control Settings\")\n",
        "\n",
        "\n",
        "        # Get samples for this class\n",
        "        class_mask = y_train_balanced == class_label\n",
        "        class_samples = X_train_sp.loc[class_mask]\n",
        "\n",
        "        if len(class_samples) > 0:\n",
        "            # Get top 4 most important features\n",
        "            top_features = importance_df.head(4)['SP_Feature'].tolist()\n",
        "\n",
        "            print(\"\\nRecommended ranges (25th-75th percentile):\\n\")\n",
        "            for feature in top_features:\n",
        "                if feature in class_samples.columns:\n",
        "                    q25 = class_samples[feature].quantile(0.25)\n",
        "                    q75 = class_samples[feature].quantile(0.75)\n",
        "                    median = class_samples[feature].median()\n",
        "\n",
        "                    print(f\"  {feature}:\")\n",
        "                    print(f\"    Range: {q25:.1f} to {q75:.1f}\")\n",
        "                    print(f\"    Target: {median:.1f}\")\n",
        "                    print()\n",
        "\n",
        "    # Simple IF-THEN rules\n",
        "\n",
        "    print(\"SIMPLE IF-THEN RULES (Extracted from Decision Tree)\")\n",
        "\n",
        "\n",
        "    # Get the most important feature for splitting\n",
        "    top_feature = importance_df.iloc[0]['SP_Feature']\n",
        "    second_feature = importance_df.iloc[1]['SP_Feature'] if len(importance_df) > 1 else None\n",
        "\n",
        "    print(f\"\\nBased on most important features: {top_feature}\")\n",
        "    if second_feature:\n",
        "        print(f\"and {second_feature}\\n\")\n",
        "\n",
        "    for class_label in sorted(y_train_balanced.unique()):\n",
        "        class_mask = y_train_balanced == class_label\n",
        "        class_samples = X_train_sp.loc[class_mask]\n",
        "\n",
        "        if len(class_samples) > 0 and top_feature in class_samples.columns:\n",
        "            q25 = class_samples[top_feature].quantile(0.25)\n",
        "            q75 = class_samples[top_feature].quantile(0.75)\n",
        "\n",
        "            print(f\"\\nRULE {class_label}: For Class {class_label}\")\n",
        "            print(f\"  IF {top_feature} is between {q25:.1f} and {q75:.1f}\")\n",
        "\n",
        "            if second_feature and second_feature in class_samples.columns:\n",
        "                q25_2 = class_samples[second_feature].quantile(0.25)\n",
        "                q75_2 = class_samples[second_feature].quantile(0.75)\n",
        "                print(f\"  AND {second_feature} is between {q25_2:.1f} and {q75_2:.1f}\")\n",
        "\n",
        "            print(f\"  THEN predict Class {class_label}\")\n",
        "\n",
        "    # Summary table\n",
        "\n",
        "    print(\"QUICK REFERENCE TABLE\")\n",
        "\n",
        "\n",
        "    summary_data = []\n",
        "    for class_label in sorted(y_train_balanced.unique()):\n",
        "        class_mask = y_train_balanced == class_label\n",
        "        class_samples = X_train_sp.loc[class_mask]\n",
        "\n",
        "        row = {'Class': class_label}\n",
        "        for feature in importance_df.head(3)['SP_Feature'].tolist():\n",
        "            if feature in class_samples.columns:\n",
        "                q25 = class_samples[feature].quantile(0.25)\n",
        "                q75 = class_samples[feature].quantile(0.75)\n",
        "                row[feature] = f\"{q25:.0f}-{q75:.0f}\"\n",
        "        summary_data.append(row)\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"ERROR: No SP features found!\")"
      ],
      "metadata": {
        "id": "sYQcn-3DW961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5ff9c7-f10c-4108-946d-d2bdf460c66b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 SP features in selected features:\n",
            "  - FFTE Feed tank level SP\n",
            "  - FFTE Production solids SP\n",
            "  - TFE Out flow SP\n",
            "  - TFE Production solids SP\n",
            "  - TFE Vacuum pressure SP\n",
            "  - FFTE Feed flow SP\n",
            "  - FFTE Out steam temp SP\n",
            "  - FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff\n",
            "  - TFE Out flow SP_to_FFTE Feed flow SP_efficiency\n",
            "\n",
            "Training Decision Tree with SP features only...\n",
            "DECISION TREE RULES:\n",
            "|--- FFTE Feed flow SP <= 10199.96\n",
            "|   |--- FFTE Feed flow SP <= 9231.31\n",
            "|   |   |--- TFE Out flow SP <= 2172.07\n",
            "|   |   |   |--- FFTE Feed tank level SP <= 1.50\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- FFTE Feed tank level SP >  1.50\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |--- TFE Out flow SP >  2172.07\n",
            "|   |   |   |--- FFTE Production solids SP <= 41.31\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- FFTE Production solids SP >  41.31\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |--- FFTE Feed flow SP >  9231.31\n",
            "|   |   |--- TFE Production solids SP <= 63.00\n",
            "|   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= 4.27\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  4.27\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |--- TFE Production solids SP >  63.00\n",
            "|   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= -9.12\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  -9.12\n",
            "|   |   |   |   |--- class: 1\n",
            "|--- FFTE Feed flow SP >  10199.96\n",
            "|   |--- TFE Production solids SP <= 84.00\n",
            "|   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff <= -9.06\n",
            "|   |   |   |--- FFTE Out steam temp SP <= 50.12\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- FFTE Out steam temp SP >  50.12\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff >  -9.06\n",
            "|   |   |   |--- TFE Production solids SP <= 67.97\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- TFE Production solids SP >  67.97\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |--- TFE Production solids SP >  84.00\n",
            "|   |   |--- FFTE Feed flow SP <= 10444.00\n",
            "|   |   |   |--- class: 2\n",
            "|   |   |--- FFTE Feed flow SP >  10444.00\n",
            "|   |   |   |--- class: 0\n",
            "\n",
            "FEATURE IMPORTANCE:\n",
            "                                          SP_Feature  Importance\n",
            "5                                  FFTE Feed flow SP    0.359941\n",
            "3                           TFE Production solids SP    0.237431\n",
            "7  FFTE Out steam temp SP_minus_FFTE Heat tempera...    0.202374\n",
            "6                             FFTE Out steam temp SP    0.068767\n",
            "2                                    TFE Out flow SP    0.049885\n",
            "1                          FFTE Production solids SP    0.042016\n",
            "0                            FFTE Feed tank level SP    0.039586\n",
            "4                             TFE Vacuum pressure SP    0.000000\n",
            "8    TFE Out flow SP_to_FFTE Feed flow SP_efficiency    0.000000\n",
            "RECOMMENDED SET POINT RANGES FOR EACH CLASS\n",
            "CLASS 0 - Recommended Control Settings\n",
            "\n",
            "Recommended ranges (25th-75th percentile):\n",
            "\n",
            "  FFTE Feed flow SP:\n",
            "    Range: 9400.0 to 10000.0\n",
            "    Target: 9500.0\n",
            "\n",
            "  TFE Production solids SP:\n",
            "    Range: 61.1 to 68.6\n",
            "    Target: 65.0\n",
            "\n",
            "  FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff:\n",
            "    Range: -9.4 to 0.0\n",
            "    Target: -3.2\n",
            "\n",
            "  FFTE Out steam temp SP:\n",
            "    Range: 50.0 to 50.1\n",
            "    Target: 50.0\n",
            "\n",
            "CLASS 1 - Recommended Control Settings\n",
            "\n",
            "Recommended ranges (25th-75th percentile):\n",
            "\n",
            "  FFTE Feed flow SP:\n",
            "    Range: 9300.0 to 10130.0\n",
            "    Target: 9500.0\n",
            "\n",
            "  TFE Production solids SP:\n",
            "    Range: 60.7 to 69.0\n",
            "    Target: 65.0\n",
            "\n",
            "  FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff:\n",
            "    Range: -9.0 to 1.2\n",
            "    Target: -2.9\n",
            "\n",
            "  FFTE Out steam temp SP:\n",
            "    Range: 50.0 to 50.0\n",
            "    Target: 50.0\n",
            "\n",
            "CLASS 2 - Recommended Control Settings\n",
            "\n",
            "Recommended ranges (25th-75th percentile):\n",
            "\n",
            "  FFTE Feed flow SP:\n",
            "    Range: 9500.0 to 10300.0\n",
            "    Target: 10130.0\n",
            "\n",
            "  TFE Production solids SP:\n",
            "    Range: 63.0 to 71.0\n",
            "    Target: 68.0\n",
            "\n",
            "  FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff:\n",
            "    Range: -6.1 to 1.4\n",
            "    Target: -1.7\n",
            "\n",
            "  FFTE Out steam temp SP:\n",
            "    Range: 50.0 to 50.0\n",
            "    Target: 50.0\n",
            "\n",
            "SIMPLE IF-THEN RULES (Extracted from Decision Tree)\n",
            "\n",
            "Based on most important features: FFTE Feed flow SP\n",
            "and TFE Production solids SP\n",
            "\n",
            "\n",
            "RULE 0: For Class 0\n",
            "  IF FFTE Feed flow SP is between 9400.0 and 10000.0\n",
            "  AND TFE Production solids SP is between 61.1 and 68.6\n",
            "  THEN predict Class 0\n",
            "\n",
            "RULE 1: For Class 1\n",
            "  IF FFTE Feed flow SP is between 9300.0 and 10130.0\n",
            "  AND TFE Production solids SP is between 60.7 and 69.0\n",
            "  THEN predict Class 1\n",
            "\n",
            "RULE 2: For Class 2\n",
            "  IF FFTE Feed flow SP is between 9500.0 and 10300.0\n",
            "  AND TFE Production solids SP is between 63.0 and 71.0\n",
            "  THEN predict Class 2\n",
            "QUICK REFERENCE TABLE\n",
            " Class FFTE Feed flow SP TFE Production solids SP FFTE Out steam temp SP_minus_FFTE Heat temperature 1_diff\n",
            "     0        9400-10000                    61-69                                                      -9-0\n",
            "     1        9300-10130                    61-69                                                      -9-1\n",
            "     2        9500-10300                    63-71                                                      -6-1\n"
          ]
        }
      ]
    }
  ]
}