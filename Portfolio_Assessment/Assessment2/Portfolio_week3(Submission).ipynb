{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RhTSU1xI_tb_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.signal import find_peaks\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MlmNsdF7_yLx",
        "outputId": "ef72eca0-1962-48a0-db79-29bba87e7609"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STUDENT_NUMBER_ENDING = 9"
      ],
      "metadata": {
        "id": "HW87gUDRAfZl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA COLLECTION"
      ],
      "metadata": {
        "id": "ajSJNJWAAmbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define column mappings based on student number ending (corrected column names)\n",
        "column_mapping = {\n",
        "    0: (['Neck x', 'Neck y', 'Neck z'], ['Head x', 'Head y', 'Head z']),\n",
        "    1: (['Right Shoulder x', 'Right Shoulder y', 'Right Shoulder z'],\n",
        "        ['Left Shoulder x', 'Left Shoulder y', 'Left Shoulder z']),\n",
        "    2: (['Right Upper Arm x', 'Right Upper Arm y', 'Right Upper Arm z'],\n",
        "        ['Left Upper Arm x', 'Left Upper Arm y', 'Left Upper Arm z']),\n",
        "    3: (['Right Forearm x', 'Right Forearm y', 'Right Forearm z'],\n",
        "        ['Left Forearm x', 'Left Forearm y', 'Left Forearm z']),\n",
        "    4: (['Right Hand x', 'Right Hand y', 'Right Hand z'],\n",
        "        ['Left Hand x', 'Left Hand y', 'Left Hand z']),\n",
        "    5: (['Right Upper Leg x', 'Right Upper Leg y', 'Right Upper Leg z'],\n",
        "        ['Left Upper Leg x', 'Left Upper Leg y', 'Left Upper Leg z']),\n",
        "    6: (['Right Lower Leg x', 'Right Lower Leg y', 'Right Lower Leg z'],\n",
        "        ['Left Lower Leg x', 'Left Lower Leg y', 'Left Lower Leg z']),\n",
        "    7: (['Right Foot x', 'Right Foot y', 'Right Foot z'],\n",
        "        ['Left Foot x', 'Left Foot y', 'Left Foot z']),\n",
        "    8: (['Right Toe x', 'Right Toe y', 'Right Toe z'],\n",
        "        ['Left Toe x', 'Left Toe y', 'Left Toe z']),\n",
        "    9: (['L5 x', 'L5 y', 'L5 z'], ['T12 x', 'T12 y', 'T12 z'])\n",
        "}"
      ],
      "metadata": {
        "id": "3xgY7WapApN4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data files\n",
        "boning_data = pd.read_csv(dataset_path + 'Boning.csv')\n",
        "slicing_data = pd.read_csv(dataset_path + 'Slicing.csv')"
      ],
      "metadata": {
        "id": "B5xtVi9GArwM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add class labels\n",
        "boning_data['class'] = 0  # boning\n",
        "slicing_data['class'] = 1  # slicing\n",
        "\n",
        "# Get the columns for this student\n",
        "col_set1, col_set2 = column_mapping[STUDENT_NUMBER_ENDING]\n",
        "\n",
        "# Extract required columns (Frame + column sets + class)\n",
        "required_columns = ['Frame'] + col_set1 + col_set2 + ['class']\n",
        "\n",
        "# Extract columns from both datasets\n",
        "boning_extracted = boning_data[required_columns]\n",
        "slicing_extracted = slicing_data[required_columns]\n",
        "\n",
        "# Combine datasets\n",
        "combined_data = pd.concat([boning_extracted, slicing_extracted], ignore_index=True)\n",
        "print(f\"Data shape: {combined_data.shape}\")\n",
        "\n",
        "# Save the extracted data\n",
        "combined_data.to_csv('extracted_data.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4KzBYBBoAr5R",
        "outputId": "0cdb4d03-ec58-4343-812d-a6f48fb6c17c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (72060, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATE COMPOSITE COLUMNS"
      ],
      "metadata": {
        "id": "KgUzhSIABqBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create composite features for column set 1\n",
        "x1, y1, z1 = combined_data[col_set1[0]], combined_data[col_set1[1]], combined_data[col_set1[2]]\n",
        "\n",
        "combined_data['rms_xy_set1'] = np.sqrt((x1**2 + y1**2) / 2)\n",
        "combined_data['rms_yz_set1'] = np.sqrt((y1**2 + z1**2) / 2)\n",
        "combined_data['rms_zx_set1'] = np.sqrt((z1**2 + x1**2) / 2)\n",
        "combined_data['rms_xyz_set1'] = np.sqrt((x1**2 + y1**2 + z1**2) / 3)\n",
        "combined_data['roll_set1'] = 180 * np.arctan2(y1, np.sqrt(x1**2 + z1**2)) / np.pi\n",
        "combined_data['pitch_set1'] = 180 * np.arctan2(x1, np.sqrt(y1**2 + z1**2)) / np.pi"
      ],
      "metadata": {
        "id": "l2fGnU7eA6ZE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create composite features for column set 2\n",
        "x2, y2, z2 = combined_data[col_set2[0]], combined_data[col_set2[1]], combined_data[col_set2[2]]\n",
        "\n",
        "combined_data['rms_xy_set2'] = np.sqrt((x2**2 + y2**2) / 2)\n",
        "combined_data['rms_yz_set2'] = np.sqrt((y2**2 + z2**2) / 2)\n",
        "combined_data['rms_zx_set2'] = np.sqrt((z2**2 + x2**2) / 2)\n",
        "combined_data['rms_xyz_set2'] = np.sqrt((x2**2 + y2**2 + z2**2) / 3)\n",
        "combined_data['roll_set2'] = 180 * np.arctan2(y2, np.sqrt(x2**2 + z2**2)) / np.pi\n",
        "combined_data['pitch_set2'] = 180 * np.arctan2(x2, np.sqrt(y2**2 + z2**2)) / np.pi\n"
      ],
      "metadata": {
        "id": "rgMFysl-A6ch"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data shape with composite columns: {combined_data.shape}\")\n",
        "\n",
        "# Save data with composite columns\n",
        "combined_data.to_csv('composite_data.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nejfUhKBA60E",
        "outputId": "c515f254-2a21-4fa5-8594-c513ee131235"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape with composite columns: (72060, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FEATURE COMPUTATION"
      ],
      "metadata": {
        "id": "BJJTo2vCB7Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature columns (exclude Frame and class)\n",
        "feature_columns = [col for col in combined_data.columns if col not in ['Frame', 'class']]"
      ],
      "metadata": {
        "id": "PFRXddWdA62H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each class separately to create features per minute\n",
        "feature_list = []\n",
        "\n",
        "for class_val in combined_data['class'].unique():\n",
        "    class_data = combined_data[combined_data['class'] == class_val].copy()\n",
        "    class_data = class_data.reset_index(drop=True)  # Reset index for this class\n",
        "\n",
        "    # Create minute grouping within this class data (60 frames = 1 minute)\n",
        "    num_complete_minutes = len(class_data) // 60\n",
        "\n",
        "    for minute in range(num_complete_minutes):\n",
        "        # Get exactly 60 frames for this minute\n",
        "        start_idx = minute * 60\n",
        "        end_idx = start_idx + 60\n",
        "        minute_data = class_data.iloc[start_idx:end_idx]\n",
        "\n",
        "        minute_features = {\n",
        "            'minute': f\"{class_val}_{minute}\",  # Unique identifier\n",
        "            'class': class_val\n",
        "        }\n",
        "\n",
        "        # Compute statistical features for each feature column\n",
        "        for col in feature_columns:\n",
        "            values = minute_data[col].values\n",
        "\n",
        "            minute_features[f'{col}_mean'] = np.mean(values)\n",
        "            minute_features[f'{col}_std'] = np.std(values)\n",
        "            minute_features[f'{col}_min'] = np.min(values)\n",
        "            minute_features[f'{col}_max'] = np.max(values)\n",
        "            minute_features[f'{col}_auc'] = np.trapz(np.abs(values))\n",
        "\n",
        "            # Count peaks\n",
        "            peaks, _ = find_peaks(values, height=np.mean(values))\n",
        "            minute_features[f'{col}_peaks'] = len(peaks)\n",
        "\n",
        "        feature_list.append(minute_features)"
      ],
      "metadata": {
        "id": "pb47p7YdA64L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature dataframe\n",
        "features_df = pd.DataFrame(feature_list)\n",
        "\n",
        "print(f\"Features shape: {features_df.shape}\")\n",
        "print(f\"Class distribution: {features_df['class'].value_counts().to_dict()}\")\n",
        "print(f\"Total features: {len([col for col in features_df.columns if col not in ['minute', 'class']])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MqWsc8tIIsW4",
        "outputId": "634712a0-c9bc-49d4-eafb-011da9c22379"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (1201, 110)\n",
            "Class distribution: {0: 903, 1: 298}\n",
            "Total features: 108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save feature data\n",
        "features_df.to_csv('features.csv', index=False)\n",
        "print(\"Features saved to 'features.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8jGl2SZyA66K",
        "outputId": "98e9acfc-1c0a-4278-e598-73575dee33a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to 'features.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL TRAINING"
      ],
      "metadata": {
        "id": "EumccRsoCUQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = features_df.drop(['minute', 'class'], axis=1)\n",
        "y = features_df['class']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "results = {}"
      ],
      "metadata": {
        "id": "8Xe0zxysCU98"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Basic SVM - Train-Test Split (only if we have both classes)\n",
        "if len(y.unique()) >= 2:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=0.3, random_state=1, stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"After split - Train classes:\", y_train.value_counts().to_dict())\n",
        "    print(\"After split - Test classes:\", y_test.value_counts().to_dict())\n",
        "\n",
        "    clf_basic = svm.SVC(random_state=1)\n",
        "    clf_basic.fit(X_train, y_train)\n",
        "    y_pred_basic = clf_basic.predict(X_test)\n",
        "    basic_train_test = accuracy_score(y_test, y_pred_basic)\n",
        "\n",
        "    print(f\"Basic SVM train-test accuracy: {basic_train_test:.4f}\")\n",
        "else:\n",
        "    print(\"Cannot proceed with training - need both classes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZTOd_WLECVAA",
        "outputId": "9133c69f-5858-47cf-bbf8-9a381b545064"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After split - Train classes: {0: 632, 1: 208}\n",
            "After split - Test classes: {0: 271, 1: 90}\n",
            "Basic SVM train-test accuracy: 0.8670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Basic SVM - Cross Validation\n",
        "scores_basic_cv = cross_val_score(clf_basic, X_scaled, y, cv=10)\n",
        "basic_cv = scores_basic_cv.mean()\n",
        "\n",
        "results['Original features'] = {\n",
        "    'train_test': basic_train_test,\n",
        "    'cross_val': basic_cv\n",
        "}"
      ],
      "metadata": {
        "id": "jW-BfzYZCVCP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(svm.SVC(random_state=1), param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_clf = grid_search.best_estimator_\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eKTcRnouCVL8",
        "outputId": "6470fb88-91e7-460d-a62a-8bb55450dcb1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Tuned SVM - Train-Test Split\n",
        "y_pred_tuned = best_clf.predict(X_test)\n",
        "tuned_train_test = accuracy_score(y_test, y_pred_tuned)"
      ],
      "metadata": {
        "id": "maEIi3L3CVOB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Tuned SVM - Cross Validation\n",
        "scores_tuned_cv = cross_val_score(best_clf, X_scaled, y, cv=10)\n",
        "tuned_cv = scores_tuned_cv.mean()\n",
        "\n",
        "results['With hyper-parameter tuning'] = {\n",
        "    'train_test': tuned_train_test,\n",
        "    'cross_val': tuned_cv\n",
        "}\n"
      ],
      "metadata": {
        "id": "ARBDMTEcCVQK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Feature Selection (10 best features)\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "\n",
        "X_train_sel, X_test_sel, _, _ = train_test_split(X_selected, y, test_size=0.3, random_state=1)\n",
        "\n",
        "clf_selected = svm.SVC(**grid_search.best_params_, random_state=1)\n",
        "clf_selected.fit(X_train_sel, y_train)\n",
        "y_pred_selected = clf_selected.predict(X_test_sel)\n",
        "selected_train_test = accuracy_score(y_test, y_pred_selected)\n",
        "\n",
        "scores_selected_cv = cross_val_score(clf_selected, X_selected, y, cv=10)\n",
        "selected_cv = scores_selected_cv.mean()\n",
        "\n",
        "results['With feature selection and hyper parameter tuning'] = {\n",
        "    'train_test': selected_train_test,\n",
        "    'cross_val': selected_cv\n",
        "}"
      ],
      "metadata": {
        "id": "q9fQ3ke5CVSE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. PCA (10 components)\n",
        "pca = PCA(n_components=10)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_train_pca, X_test_pca, _, _ = train_test_split(X_pca, y, test_size=0.3, random_state=1)\n",
        "\n",
        "clf_pca = svm.SVC(**grid_search.best_params_, random_state=1)\n",
        "clf_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = clf_pca.predict(X_test_pca)\n",
        "pca_train_test = accuracy_score(y_test, y_pred_pca)\n",
        "\n",
        "scores_pca_cv = cross_val_score(clf_pca, X_pca, y, cv=10)\n",
        "pca_cv = scores_pca_cv.mean()\n",
        "\n",
        "results['With PCA and hyper parameter tuning'] = {\n",
        "    'train_test': pca_train_test,\n",
        "    'cross_val': pca_cv\n",
        "}\n"
      ],
      "metadata": {
        "id": "fiVJXSEiCldb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Other Classifiers\n",
        "other_results = {}"
      ],
      "metadata": {
        "id": "afa4YwHIClfn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD Classifier\n",
        "sgd_clf = SGDClassifier(random_state=1, max_iter=1000)\n",
        "sgd_clf.fit(X_train, y_train)\n",
        "y_pred_sgd = sgd_clf.predict(X_test)\n",
        "sgd_train_test = accuracy_score(y_test, y_pred_sgd)\n",
        "sgd_cv_scores = cross_val_score(sgd_clf, X_scaled, y, cv=10)\n",
        "sgd_cv = sgd_cv_scores.mean()\n",
        "other_results['SGD'] = {'train_test': sgd_train_test, 'cross_val': sgd_cv}"
      ],
      "metadata": {
        "id": "s8TiixbKClhR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "rf_train_test = accuracy_score(y_test, y_pred_rf)\n",
        "rf_cv_scores = cross_val_score(rf_clf, X_scaled, y, cv=10)\n",
        "rf_cv = rf_cv_scores.mean()\n",
        "other_results['RandomForest'] = {'train_test': rf_train_test, 'cross_val': rf_cv}"
      ],
      "metadata": {
        "id": "eFKWyzNvCqKE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Classifier\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=1)\n",
        "mlp_clf.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp_clf.predict(X_test)\n",
        "mlp_train_test = accuracy_score(y_test, y_pred_mlp)\n",
        "mlp_cv_scores = cross_val_score(mlp_clf, X_scaled, y, cv=10)\n",
        "mlp_cv = mlp_cv_scores.mean()\n",
        "other_results['MLP'] = {'train_test': mlp_train_test, 'cross_val': mlp_cv}"
      ],
      "metadata": {
        "id": "itdANQb7CqML"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== SVM MODELS SUMMARY TABLE ===\")\n",
        "print(f\"{'SVM Model':<50} {'Train-test split':<20} {'Cross-validation':<20}\")\n",
        "print(\"-\" * 90)\n",
        "for model_name, scores in results.items():\n",
        "    train_test_acc = scores['train_test'] * 100\n",
        "    cross_val_acc = scores['cross_val'] * 100\n",
        "    print(f\"{model_name:<50} {train_test_acc:>18.2f}% {cross_val_acc:>18.2f}%\")\n",
        "\n",
        "print(\"\\n=== ALL CLASSIFIERS COMPARISON ===\")\n",
        "# Add best SVM to other results for comparison\n",
        "best_svm_key = max(results.keys(), key=lambda k: results[k]['train_test'])\n",
        "other_results['SVM (Best)'] = results[best_svm_key]\n",
        "\n",
        "print(f\"{'Model':<15} {'Train-test split':<20} {'Cross-validation':<20}\")\n",
        "print(\"-\" * 55)\n",
        "for model_name, scores in other_results.items():\n",
        "    train_test_acc = scores['train_test'] * 100\n",
        "    cross_val_acc = scores['cross_val'] * 100\n",
        "    print(f\"{model_name:<15} {train_test_acc:>18.2f}% {cross_val_acc:>18.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LbcwvmNCCu1k",
        "outputId": "7c010ac8-23ef-411c-cac6-3d6be3c311e2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SVM MODELS SUMMARY TABLE ===\n",
            "SVM Model                                          Train-test split     Cross-validation    \n",
            "------------------------------------------------------------------------------------------\n",
            "Original features                                               86.70%              84.93%\n",
            "With hyper-parameter tuning                                     85.32%              85.10%\n",
            "With feature selection and hyper parameter tuning               75.07%              81.68%\n",
            "With PCA and hyper parameter tuning                             75.07%              84.10%\n",
            "\n",
            "=== ALL CLASSIFIERS COMPARISON ===\n",
            "Model           Train-test split     Cross-validation    \n",
            "-------------------------------------------------------\n",
            "SGD                          84.49%              82.68%\n",
            "RandomForest                 85.04%              84.51%\n",
            "MLP                          84.21%              81.93%\n",
            "SVM (Best)                   86.70%              84.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL SELECTION"
      ],
      "metadata": {
        "id": "Zf-nnpjeC1ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best SVM model\n",
        "best_svm_model = max(results.keys(), key=lambda k: results[k]['cross_val'])\n",
        "best_svm_score = results[best_svm_model]['cross_val']"
      ],
      "metadata": {
        "id": "9A55TCtgCqOL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best overall model\n",
        "best_overall_model = max(other_results.keys(), key=lambda k: other_results[k]['cross_val'])\n",
        "best_overall_score = other_results[best_overall_model]['cross_val']\n",
        "\n",
        "print(f\"\\nBest SVM Model: {best_svm_model} (CV: {best_svm_score:.4f})\")\n",
        "print(f\"Best Overall Model: {best_overall_model} (CV: {best_overall_score:.4f})\")\n",
        "\n",
        "print(\"\\n=== MODEL SELECTION ANSWERS ===\")\n",
        "print(\"1) Best SVM model:\", best_svm_model)\n",
        "print(\"   Reason: Highest cross-validation accuracy among SVM variants\")\n",
        "print(\"2) Best ML model:\", best_overall_model)\n",
        "print(\"   Reason: Highest overall performance across all tested algorithms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a1T81sfNC56m",
        "outputId": "14bb4175-773b-48d3-aaeb-a691fcf39b2d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best SVM Model: With hyper-parameter tuning (CV: 0.8510)\n",
            "Best Overall Model: SVM (Best) (CV: 0.8493)\n",
            "\n",
            "=== MODEL SELECTION ANSWERS ===\n",
            "1) Best SVM model: With hyper-parameter tuning\n",
            "   Reason: Highest cross-validation accuracy among SVM variants\n",
            "2) Best ML model: SVM (Best)\n",
            "   Reason: Highest overall performance across all tested algorithms\n"
          ]
        }
      ]
    }
  ]
}